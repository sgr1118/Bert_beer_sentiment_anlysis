# Project : Beer Sentiment Classifier and Keyphrase Extraction
<img src="https://img.shields.io/badge/Python-3.8-blue"><img src="https://img.shields.io/badge/Transformers-4.16.2-blue"><img src="https://img.shields.io/badge/-Colab-yellow)"><img src="https://img.shields.io/badge/Pytorch-blue">

## í”„ë¡œì íŠ¸ ì†Œê°œ
- ë³¸ í”„ë¡œì íŠ¸ëŠ” ë¦¬ë·° ë°ì´í„° ê°ì •ë¶„ì„ê³¼ í•µì‹¬ ë¬¸êµ¬ë¥¼ ì¶”ì¶œí•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
- ë°ì´í„° ìˆ˜ì§‘, ë¼ë²¨ë§, ëª¨ë¸ë§, ë°ì´í„° ì¦ê°•, ë¬¸êµ¬ ì¶”ì¶œë°©ë²•ì„ ì „ë¶€ ë‹¤ë£¹ë‹ˆë‹¤.

## í”„ë¡œì íŠ¸ ëª©í‘œ
### ëª¨ë¸ì˜ ê°ì • ë¶„ì„ ì„±ëŠ¥ì„ Precision ê¸°ì¤€ 0.9 ì´ìƒ ë‹¬ì„±
### ì‚¬ìš©ìê°€ ì„ íƒí•œ ë§¥ì£¼ì— ëŒ€í•œ í•µì‹¬ ë¬¸êµ¬ì„ ì¶”ì¶œí•˜ëŠ” ë°©ë²• ì œê³µ

## ê°ì • ë¶„ë¥˜ ë° í•µì‹¬ ë¬¸êµ¬ ì¶”ì¶œ Demo

## ì‚¬ì „ ì¤€ë¹„
``` c 
!git clone https://github.com/sgr1118/Beer_Sentiment_analysis.git
pip install -r requirements.txt
```

## ì‚¬ìš©ë²• ì˜ˆì‹œ
### Use to Pre_Trained_Model [[colab]](https://colab.research.google.com/drive/1JhGI6jTBXHxkXtQKYtA__V0kQYu1mlTk#scrollTo=tuOrfo06qbsv)

``` c 
import torch
from transformers import BertTokenizerFast, BertForSequenceClassification
from torch.nn.functional import softmax
import matplotlib.pyplot as plt

# ëª¨ë¸ ë¡œë“œ
model = BertForSequenceClassification.from_pretrained('GiRak/beer-sentiment-bert') # HuggingFace ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ì—…ë¡œë“œ
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = model.to(device)

# í† í¬ë‚˜ì´ì € ì´ˆê¸°í™”
tokenizer = BertTokenizerFast.from_pretrained('GiRak/beer-sentiment-bert') # HuggingFace ì‚¬ì „ í•™ìŠµ ëª¨ë¸ ì—…ë¡œë“œ

def analyze_sentiment(sentence):
    # ë¬¸ì¥ì„ í† í¬ë‚˜ì´ì§•í•˜ê³  ëª¨ë¸ ì…ë ¥ìœ¼ë¡œ ë³€í™˜
    inputs = tokenizer(sentence, return_tensors='pt')
    inputs = inputs.to(device)

    # ëª¨ë¸ì„ í†µí•´ ê°ì • ë¶„ë¥˜ ìˆ˜í–‰
    outputs = model(**inputs)
    logits = outputs.logits
    probabilities = softmax(logits, dim=1)

    # ê°ì • ë¶„ë¥˜ í™•ë¥  ì¶”ì¶œ
    sentiment_labels = ['Negative', 'Positive']
    sentiment_probabilities = {label: probability.item() for label, probability in zip(sentiment_labels, probabilities[0])}

    return sentiment_probabilities

sentences = ['I took a sip and immediately discarded it. How could a beer have such a strong cinnamon flavor?']

# Lists to store probabilities
positive_probs = []
negative_probs = []

for sentence in sentences:
    sentiment_probabilities = analyze_sentiment(sentence)
    positive_prob = sentiment_probabilities['Positive'] * 100
    negative_prob = sentiment_probabilities['Negative'] * 100

    positive_probs.append(positive_prob)
    negative_probs.append(negative_prob)

    print("Sentence:", sentence)
    print("Positive Probability:", int(positive_prob), "%")
    print("Negative Probability:", int(negative_prob), "%")

# Plotting
x = ['Positive', 'Negative']

plt.bar(x, [positive_probs[0], negative_probs[0]], color=['green', 'red'])
plt.xlabel('Sentiment')
plt.ylabel('Probability (%)')
plt.title('Sentiment Analysis Result')
plt.tight_layout()
plt.show()
```

### í‚¤ì›Œë“œ ë° í•µì‹¬ ë¬¸êµ¬ ì¶”ì¶œ
``` c 
# Load the model
kw_model = KeyBERT('all-mpnet-base-v2')

# Use KeyphraseCountVectorize
from tqdm import tqdm

def apply_keybert(sentence):
    keywords = kw_model.extract_keywords(sentence, vectorizer=KeyphraseCountVectorizer(), stop_words='english', top_n=3)
    return ', '.join([keyword for keyword, score in keywords]) # í‚¤ì›Œë“œëŠ” ì¤‘ìš”ë„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ìµœëŒ€ 3ê°œê¹Œì§€ ì €ì¥ëœë‹¤.

# Creating Columns and Storing Keywords
df['keywords'] = df['Review'].apply(apply_keybert)

# Counting Keywords and Keyphrase

from collections import Counter

# ëª¨ë“  ì¸ë±ìŠ¤ì˜ 'keywords' ì»¬ëŸ¼ì„ í•©ì³ì„œ ë‹¨ì–´ë“¤ì„ ì¹´ìš´íŠ¸í•˜ëŠ” í•¨ìˆ˜
def count_all_keywords(dataframe):
    all_keywords = dataframe['keywords'].str.split(', ').sum()
    keyword_counts = Counter(all_keywords)
    sorted_keyword_counts = keyword_counts.most_common() # í‚¤ì›Œë“œ ë¹ˆë„ê°€ ë§ì€ ìˆœìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•œë‹¤.
    return sorted_keyword_counts

# ëª¨ë“  ì¸ë±ìŠ¤ì˜ 'keywords' ì»¬ëŸ¼ì— ìˆëŠ” ë‹¨ì–´ë“¤ì„ ì¹´ìš´íŠ¸
sorted_all_keyword_counts = count_all_keywords(beer_Wired_iStout_pre)
```
---
## Reference
#### [1. Hugging_Face_T5_Guide](https://huggingface.co/docs/transformers/model_doc/t5)
#### [2. T5_Paper](https://arxiv.org/pdf/1910.10683v3.pdf)
#### [3. SimpleT5 github](https://github.com/Shivanandroy/simpleT5/tree/main)
#### [4. Data_Labeling_VADER](https://medium.com/analytics-vidhya/sentiment-analysis-with-vader-label-the-unlabeled-data-8dd785225166)
#### [5. Data_Labeling_GPT](https://towardsdatascience.com/can-chatgpt-compete-with-domain-specific-sentiment-analysis-machine-learning-models-cdcd9937b460)
#### [6. Data_Labeling_Alpaca](https://www.youtube.com/watch?v=JzBR8oieyy8&t=117s)
#### [7. The Most Common Evaluation Metrics In NLP](https://medium.com/towards-data-science/the-most-common-evaluation-metrics-in-nlp-ced6a763ac8b)
#### [8. Pytorch Multi GPU](https://medium.com/daangn/pytorch-multi-gpu-%ED%95%99%EC%8A%B5-%EC%A0%9C%EB%8C%80%EB%A1%9C-%ED%95%98%EA%B8%B0-27270617936b)
#### [9. Data Augmentation ê¸°ë²•](https://maelfabien.github.io/machinelearning/NLP_8/#when-should-we-use-data-augmentation)
#### [10. Gradio ì‹œì—°](https://levelup.gitconnected.com/sharing-your-machine-learning-or-deep-learning-projects-with-users-with-gradio-10b42588a55d)
---
## í”„ë¡œì íŠ¸ ê²°ê³¼ë¬¼ ëª¨ìŒ

|No|ë‚´ìš©|ê¹ƒí—ˆë¸Œ|
|-|-|-|
|1|ë°ì´í„° ìˆ˜ì§‘|[ğŸ“‚](https://github.com/sgr1118/Bert_beer_sentiment_anlysis/tree/main/Data)|
|2|ë°ì´í„° ë¼ë²¨ë§|[ğŸ“‚](https://github.com/sgr1118/Bert_beer_sentiment_anlysis/tree/main/Data/Data_labeling_test)|
|3|íŒŒì¸ íŠœë‹|[ğŸ“‚](https://github.com/sgr1118/Bert_beer_sentiment_anlysis/tree/main/Models/Step1_Bert_train)|
---
## í”„ë¡œì íŠ¸ ê°œì„  ìš”êµ¬ ì‚¬í•­

### 1. ì¤‘ë¦½ ë¼ë²¨ë§ ì¶”ê°€
- ì¢€ë” ì„¸ë¶„í™”ëœ ê°ì • ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•˜ê¸°ìœ„í•´ ì¤‘ë¦½ ë¼ë²¨ë§ ê¸°ì¤€ì„ í™•ë¦½í•˜ê³  ì ìš©í•  ì˜ˆì •

### 2. í•µì‹¬ ë¬¸êµ¬ ì¶”ì¶œ ì†ë„ ì¦ê°€
- KeyBERTë¥¼ ì‚¬ìš©í•˜ì—¬ í•µì‹¬ ë¬¸êµ¬ ì¶”ì¶œ ì‹œê°„ì´ ë°ì´í„°ê°€ ë§ì•„ì§ˆìˆ˜ë¡ ê¸¸ì–´ì§„ë‹¤. ì‹¤ì‹œê°„ ì‘ë‹µìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ê¸° í˜ë“¤ë‹¤ëŠ” ë‹¨ì ì´ìˆë‹¤.

## í”„ë¡œì íŠ¸ í›„ì› : (ì£¼)ëª¨ë‘ì˜ì—°êµ¬ì†Œ, K-ë””ì§€í„¸ í”Œë«í¼
---
ë³¸ í”„ë¡œì íŠ¸ëŠ” ëª¨ë‘ì˜ì—°êµ¬ì†Œì™€ K-ë””ì§€í„¸ í”Œë«í¼ìœ¼ë¡œë¶€í„° ì§€ì›ë°›ì•˜ìŠµë‹ˆë‹¤.
