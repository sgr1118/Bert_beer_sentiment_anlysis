{"cells":[{"cell_type":"markdown","metadata":{},"source":["\\* Keyphrase, candidats 등 문맥을 고려해 '키워드'로 통칭"]},{"cell_type":"markdown","metadata":{"id":"NTE4DdCyolS3"},"source":["## ■ KeyBERT 참고 문헌\n","\n","> [- Keyword Extraction with BERT](https://towardsdatascience.com/keyword-extraction-with-bert-724efca412ea)  \n","> [- BERT 변환기와 명사구를 사용한 핵심구 추출](https://medium.com/towards-data-science/enhancing-keybert-keyword-extraction-results-with-keyphrasevectorizers-3796fa93f4db)  \n","> [- KeyBERT로 관련 키워드를 추출하는 방법](https://towardsdatascience.com/how-to-extract-relevant-keywords-with-keybert-6e7b3cf889ae)  \n","> [- KeyBERT Git](https://github.com/MaartenGr/KeyBERT)  \n","  \n","---"]},{"cell_type":"markdown","metadata":{},"source":["## ■ KeyBERT 이론 설명"]},{"cell_type":"markdown","metadata":{},"source":["### - 통계 기반 추출 방식? 의미론적 추출 방식!\n","- 통계 기반 추출 방식에는 RAKE, YAKE!, TF-IDF 방식 등이 있음\n","- 통계 기반 추출의 경우, 글 전체의 의미가 반드시 고려되진 않음"]},{"cell_type":"markdown","metadata":{"id":"fONlp4oRka-8"},"source":["### - 작동 원리(KeyBert의 작동원리)\n","1\\) 사전 학습된 언어 모델을 정의\n","- KeyBERT는 임베딩을 위해 기본적으로 BERT를 사용하지만 BERT 기반의 많은 사전 학습 언어 모델을 지원\n","- 창작자는 당시 senetence-transformer 패키지의 DistilBERT 모델을 사용\n","- DistilBERT는 기존 BERT보다 좀 더 가볍지만 성능은 그에 준하는 모델 (BERT가 큰 규모의 문서에는 효율적이지 않기에 상대적으로 가벼운 것 사용)\n","\n","2\\) 키워드 및 표현식 추출  \n","- Bag Of Words(=CountVectorizer) 기술을 사용하여 동일한 문서에 키워드들을 추출  \n","\\* CountVectorizer: 명사구 초점에서 벗어나서 키워드 길이 조정 및 핵심 구문 만들 수 있음, 빠른 stopwords 제거  \n","\\* n_gram_range: 키워드(구문)의 길이 지정 가능, stopwords 제거하지 않으면 키 구문이 길게 나올 수도 있음\n","  \n","![](https://miro.medium.com/v2/resize:fit:828/0*Vg6abk6F1H6JfwDB)\n","<center>1,2) 키워드 및 표현식 추출</center>\n","\n","<hr style=\"border: none; border-top: 2px dashed gray;\"/>\n","  \n","3\\) 텍스트 임베딩\n","- 그림2번 처럼 입력된 키워드들은 사전 학습된 언어 모델을 통해 임베딩 벡터로 변환\n","- 이때 사전 학습 모델로 임베딩 (본 문서에는 DistilBERT)\n","\n","![](https://miro.medium.com/v2/resize:fit:786/0*9B-eJJR6p4jb_-uA)\n","<center>3) 텍스트 임베딩</center>\n","  \n","<hr style=\"border: none; border-top: 2px dashed gray;\"/>\n","  \n","4\\) 키워드 유사도 계산\n","> [코사인 유사도란? (Cosine Similarity)](https://wikidocs.net/24603)  \n","- 키워드와 문서가 같은 공간에 표시되므로 KeyBERT는 키워드 임베딩과 문서 임베딩 간의 코사인 유사도를 계산\n","- 그 이후 문서와 키워드간 유사도가 높은 순서대로 나열됨\n","- 단, 나열된 키워드들은 n_gram으로 묶었을 때 각 후보별로 의미가 너무 유사하는 문제 발생할 수 있음\n","\n","![](https://miro.medium.com/v2/resize:fit:786/0*ocfR8WLpwRI_7tGi)\n","<center>4)코사인 유사도 계산</center>\n","  \n","<hr style=\"border: none; border-top: 2px dashed gray;\"/>\n","  \n","5\\) 키워드 Diversification\n","(추출된 키워드의 다양성을 올리는 작업)\n","\n","- Max Sum Similarity (MSS) - 최대 합계 거리\n","  - 키워드들의 유사도를 고려하여 문서에서 가장 관련성이 높은 키워드들을 선택하는 알고리즘\n","  - 각 키워드와 문서 간의 코사인 유사도를 계산하고, 문서에서 키워드들의 코사인 유사도 합이 최대가 되도록 키워드들을 선택\n","  - 즉, 데이터(후보) 쌍 간의 거리가 최대가 되도록 하는 방법  \n","\\* nr_candidate를 늘리면 다양성이 증가하지만 너무 높을 경우 표현력 저하  \n","\\** nr_candidate는 전체 고유 단어 수의 20% 미만을 추천\n","\n","- Maximal Marginal Relevance (MMR) - 최대최근 관련성\n","  - MMR은 키워드들의 중복을 최소화하면서 다양한 토픽의 키워드들을 선택하는 알고리즘입니다.\n","  - 이 알고리즘은 관련성과 다양성 사이의 trade-off를 고려합니다. \n","  - 먼저, 가장 관련성이 높은 키워드를 선택하고, 이후 다른 키워드들 중에서 가장 관련성이 높은 키워드들과의 유사도와 중복을 최소화하면서 다양한 키워드들을 선택합니다. 이를 통해 문서의 다양한 측면을 파악할 수 있도록 합니다.\n","\\* EmbedRank 알고리즘 기반\n","\\** diversity 증감으로 조절 가능"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["## ■ Enhanced KeyBERT"]},{"cell_type":"markdown","metadata":{},"source":["### \\- ❗임베딩 단계 이전의 문서로부터 키워드를 추출하는 방식에는 문제가 있음\n","- 최적의 n_gram 범위를 모르므로 적절한 범위를 찾는데 시간↑\n","- 추출된 키워드의 문맥과 문법 구조가 부정확할 수 있음\n","  \n","### \\- 해결방법: KeyBERT의 키워드 추출을 KeyphraseVectorizer 패키지와 함께 사용\n","- 전체 문서에 spaCy 패키지를 활용하여 각 토큰별로 품사 태그를 달고, 정규식을 이용해서 해당하는 구문 추출\n","- 장점: 사용자가 정의한 Simple n_gram 대신에 문법, 문맥적으로 더 정확한 키 구문을 얻을 수 있음\n","  \n","### \\- 작동방식 \n","※ 기본적으로 모든 Parameter가 English에 맞춰져 있음\n","\n","1\\) 전체 문서 텍스트에 토큰별로 spaCy 품사 태그가 달림\n","\n","2\\) 품사 태그가 미리 정의된 정규 표현식 패턴과 일치하는 키워드를 추출  \n","\\* 기본적으로 0 이상의 형용사와 1개 이상의 명사로 구성된 키워드 추출 (기본 정규식 패턴: '<J.*>*<N.*>+')  \n","\n","3\\) 추출된 키워드들을 document-keyphrase matrix로 변환  \n","\\* document-keyphrase matrix: 문서의 모음에서 특정 구문(=키워드)가 얼마나 자주 등장하는지를 나타내는 수학적 행렬\n","\\* 각 열(column)은 개별 구문을, 각 행(row)은 개별 문서를, 그 교차점에 있는 값(value)은 해당 문서에서 해당 구문이 얼마나 자주 등장하는지(즉, 빈도수)를 나타냄\n","\n","4\\) 추출된 키워드는 이후 임베딩 생성 및 유사도 계산을 위해 KeyBERT로 전달  \n","\\* 분산 표현하여 각 키워드 간 의미적 유사성을 벡터화(임베딩) [*분산 표현?](https://wikidocs.net/22660)  \n","\n","5\\) 각 문서와 가장 유사한 키워드 상위 n개를 나열하여 각 문장을 키워드로 묘사\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["---"]},{"cell_type":"markdown","metadata":{},"source":["## ■ KeyBERT 구현"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uFJYNUzWgv-c"},"outputs":[],"source":["# !pip install keybert\n","# !pip install keyphrase-vectorizers"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":596,"status":"ok","timestamp":1691342109485,"user":{"displayName":"GR Son","userId":"00689596548911390893"},"user_tz":-540},"id":"asxkF3M9hqrW","outputId":"1bbb42c3-3609-4145-8118-821d42af2e20"},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Users\\user\\OneDrive - 한국항공대학교\\바탕 화면\\머신러닝\\프로젝트\\Bert_beer_sentiment_anlysis\\Data\\Preprocessed_data\n"]}],"source":["cd \"../../Data/Preprocessed_data\""]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1836,"status":"ok","timestamp":1691342398446,"user":{"displayName":"GR Son","userId":"00689596548911390893"},"user_tz":-540},"id":"Ps-BaJbp2zmj"},"outputs":[],"source":["from keybert import KeyBERT\n","from keyphrase_vectorizers import KeyphraseCountVectorizer # n_gram 대신 문맥, 문법을 고쳐주는 Vectorizer\n","# from flair.embeddings import TransformerDocumentEmbeddings # 사전학습된 임베딩을 사용하는 라이브러리\n","import pandas as pd\n","from pprint import pprint # 출력 정리 라이브러리"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review</th>\n","      <th>Beer_name</th>\n","      <th>MultinomialNB_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>This is like Budlight but with slight corn tas...</td>\n","      <td>Milwaukee's Best Light</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Strong corn flavor. Highly carbonated and no h...</td>\n","      <td>Milwaukee's Best Light</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>It just doesn't get worse than this. Brings me...</td>\n","      <td>Milwaukee's Best Light</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Beast Bleu. I shutter to think how  many cans ...</td>\n","      <td>Milwaukee's Best Light</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I wouldn't wish this beer on anyones glass.  T...</td>\n","      <td>Milwaukee's Best Light</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>94136</th>\n","      <td>Can (Jan 8, 2020 canning).\\n\\nHead is initiall...</td>\n","      <td>The Bruery Ruekeller Helles</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>94137</th>\n","      <td>Pale clear gold with thin white head.  Light h...</td>\n","      <td>The Bruery Ruekeller Helles</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>94138</th>\n","      <td>Can. Pours brilliantly clear gold with a mediu...</td>\n","      <td>The Bruery Ruekeller Helles</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>94139</th>\n","      <td>Taster at The Brewpub, Placentia, Ca. Golden w...</td>\n","      <td>The Bruery Ruekeller Helles</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>94140</th>\n","      <td>[On tap at the Bruery Tasting Room, Placentia,...</td>\n","      <td>The Bruery Ruekeller Helles</td>\n","      <td>Positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>94141 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                  Review  \\\n","0      This is like Budlight but with slight corn tas...   \n","1      Strong corn flavor. Highly carbonated and no h...   \n","2      It just doesn't get worse than this. Brings me...   \n","3      Beast Bleu. I shutter to think how  many cans ...   \n","4      I wouldn't wish this beer on anyones glass.  T...   \n","...                                                  ...   \n","94136  Can (Jan 8, 2020 canning).\\n\\nHead is initiall...   \n","94137  Pale clear gold with thin white head.  Light h...   \n","94138  Can. Pours brilliantly clear gold with a mediu...   \n","94139  Taster at The Brewpub, Placentia, Ca. Golden w...   \n","94140  [On tap at the Bruery Tasting Room, Placentia,...   \n","\n","                         Beer_name MultinomialNB_label  \n","0           Milwaukee's Best Light            Negative  \n","1           Milwaukee's Best Light            Negative  \n","2           Milwaukee's Best Light            Negative  \n","3           Milwaukee's Best Light            Negative  \n","4           Milwaukee's Best Light            Negative  \n","...                            ...                 ...  \n","94136  The Bruery Ruekeller Helles            Positive  \n","94137  The Bruery Ruekeller Helles            Positive  \n","94138  The Bruery Ruekeller Helles            Positive  \n","94139  The Bruery Ruekeller Helles            Positive  \n","94140  The Bruery Ruekeller Helles            Positive  \n","\n","[94141 rows x 3 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('Binary Classification_v4.csv')\n","df"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["Beer_name\n","8 Wired iStout                      402\n","ARK Seoulite Ale                      7\n","AleSmith Speedway Stout            1414\n","Asahi Super Dry                    1691\n","Asahi Super Dry Black                94\n","B-40 Bull Max 8%                     21\n","Bavaria 8.6 (Original)              274\n","Bavaria Pilsener / Premium Beer     792\n","Beck's                             2062\n","Beer 30 Ice                          49\n","dtype: int64"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["beer_names = df['Beer_name'].unique()\n","review_counts = df.groupby('Beer_name').size()\n","# print(beer_names)\n","review_counts.head(10)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review</th>\n","      <th>Beer_name</th>\n","      <th>MultinomialNB_label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Surprisingly little taste. It is fresh and a t...</td>\n","      <td>Asahi Super Dry</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Pours an almost honey color with an extremely ...</td>\n","      <td>Asahi Super Dry</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Smell and taste of maltiness, grass and bread....</td>\n","      <td>Asahi Super Dry</td>\n","      <td>Positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>No redeeming features of this 'beer' other tha...</td>\n","      <td>Asahi Super Dry</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>At least, there's no harsh/off-flavours. What'...</td>\n","      <td>Asahi Super Dry</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2100</th>\n","      <td>shrewd metal piece of work and a aroma. with d...</td>\n","      <td>Asahi Super Dry</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>2101</th>\n","      <td>freak color. it. equal compose Canadian-Molson...</td>\n","      <td>Asahi Super Dry</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>2102</th>\n","      <td>middling japanese beer weak/watery. suck.........</td>\n","      <td>Asahi Super Dry</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>2103</th>\n","      <td>character. only thirsty. designate smell, big ...</td>\n","      <td>Asahi Super Dry</td>\n","      <td>Negative</td>\n","    </tr>\n","    <tr>\n","      <th>2104</th>\n","      <td>possibly not ZZZZZ wholly more hops. than on. ...</td>\n","      <td>Asahi Super Dry</td>\n","      <td>Negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2105 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                 Review        Beer_name  \\\n","0     Surprisingly little taste. It is fresh and a t...  Asahi Super Dry   \n","1     Pours an almost honey color with an extremely ...  Asahi Super Dry   \n","2     Smell and taste of maltiness, grass and bread....  Asahi Super Dry   \n","3     No redeeming features of this 'beer' other tha...  Asahi Super Dry   \n","4     At least, there's no harsh/off-flavours. What'...  Asahi Super Dry   \n","...                                                 ...              ...   \n","2100  shrewd metal piece of work and a aroma. with d...  Asahi Super Dry   \n","2101  freak color. it. equal compose Canadian-Molson...  Asahi Super Dry   \n","2102  middling japanese beer weak/watery. suck.........  Asahi Super Dry   \n","2103  character. only thirsty. designate smell, big ...  Asahi Super Dry   \n","2104  possibly not ZZZZZ wholly more hops. than on. ...  Asahi Super Dry   \n","\n","     MultinomialNB_label  \n","0               Positive  \n","1               Positive  \n","2               Positive  \n","3               Negative  \n","4               Negative  \n","...                  ...  \n","2100            Negative  \n","2101            Negative  \n","2102            Negative  \n","2103            Negative  \n","2104            Negative  \n","\n","[2105 rows x 3 columns]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["############## 지정된 맥주 리뷰 df 분리 ##############\n","df_f = df[df['Beer_name'] == \"Founders Porter\"]\n","df_f.reset_index(drop = True,inplace = True)"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":499,"status":"ok","timestamp":1691342749358,"user":{"displayName":"GR Son","userId":"00689596548911390893"},"user_tz":-540},"id":"RCxBdnTAhIYJ"},"outputs":[],"source":["# # 문서 지정\n","# doc = df['Review'].iloc[0]\n","# print(doc)\n","\n","# # 지정된 맥주 리뷰 문서 지정\n","# doc = df_f['Review'].iloc[1]\n","# print(doc)\n","\n","doc = \"Not treated before for some reason. Pale, clear blond. Grassy aroma. Taste of straw and some malt. Low bitterness.\""]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Xn_dDm_v3obT"},"outputs":[],"source":["# Init KeyBERT: \"all-mpnet-base-v2\" is best Pretrained Model\n","kw_model = KeyBERT(\"all-mpnet-base-v2\")\n","\n","# You can select any model from sentence-transformers [here](https://www.sbert.net/docs/pretrained_models.html) \n","# pre-trained BERT-based models: they have shown great performance in semantic similarity and paraphrase identification respectively\n","# kw_model = KeyBERT(\"distilbert-base-nli-stsb-mean-tokens\")\n","# kw_model = KeyBERT(\"xlm-r-distilroberta-base-paraphase-v1\")"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[('grassy aroma', 0.5045),\n"," ('malt', 0.4073),\n"," ('clear blond', 0.3822),\n"," ('low bitterness', 0.3635),\n"," ('straw', 0.3272)]\n"]}],"source":["# KeyphraseCountVectorizer 기본\n","keywords = kw_model.extract_keywords(doc, vectorizer=KeyphraseCountVectorizer())\n","pprint(keywords)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"elapsed":3927,"status":"ok","timestamp":1691342789657,"user":{"displayName":"GR Son","userId":"00689596548911390893"},"user_tz":-540},"id":"x4bmM6Bf4JrO","outputId":"7c39a765-512a-4378-83d3-f8b207633eeb"},"outputs":[{"name":"stdout","output_type":"stream","text":["('front', 0.0834)\n","('full body', 0.103)\n","('hint', 0.1218)\n","('soft carbonation', 0.3384)\n","('roasted malts', 0.4614)\n"]}],"source":["# KeyphraseCountVectorizer + 최대 합계 거리\n","keywords = kw_model.extract_keywords(doc, vectorizer=KeyphraseCountVectorizer(), stop_words='english',\n","                              use_maxsum=True, nr_candidates=20, top_n=5)\n","print(*keywords, sep=\"\\n\")"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["('toffee aroma', 0.529)\n","('caramel malts', 0.4739)\n","('tan head', 0.4137)\n","('prominent taste', 0.3748)\n","('soft carbonation', 0.3384)\n"]}],"source":["# KeyphraseCountVectorizer + 최대최근 관련성\n","keywords = kw_model.extract_keywords(doc, vectorizer=KeyphraseCountVectorizer(), stop_words='english',\n","                           use_mmr=True, diversity=0.7, top_n=5)\n","print(*keywords, sep=\"\\n\")"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"elapsed":521,"status":"ok","timestamp":1691345757775,"user":{"displayName":"GR Son","userId":"00689596548911390893"},"user_tz":-540},"id":"SUqPdThcj0NC","outputId":"2822bf3d-10c8-4141-e4a5-5d4749db31cd"},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Not treated before for some reason Pale <span style=\"color: #000000; text-decoration-color: #000000; background-color: #ffff00\">clear blond</span> Grassy aroma Taste of straw and some malt Low bitterness\n","</pre>\n"],"text/plain":["Not treated before for some reason Pale \u001b[30;48;2;255;255;0mclear blond\u001b[0m Grassy aroma Taste of straw and some malt Low bitterness\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[('treated reason pale', 0.3347),\n"," ('clear blond', 0.3822),\n"," ('grassy aroma taste', 0.5152)]\n"]}],"source":["# 최대 합계 거리\n","keywords = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 3), stop_words='english',\n","                              use_maxsum=True, nr_candidates=20, top_n=3, highlight=True)\n","pprint(keywords)"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"elapsed":519,"status":"ok","timestamp":1691345775915,"user":{"displayName":"GR Son","userId":"00689596548911390893"},"user_tz":-540},"id":"2m2V9iGYk01c","outputId":"06568770-b7d5-418f-9daf-60b48a480f4a"},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Not <span style=\"color: #000000; text-decoration-color: #000000; background-color: #ffff00\">treated</span> before for for some reason Pale clear <span style=\"color: #000000; text-decoration-color: #000000; background-color: #ffff00\">blond Grassy aroma</span> of straw and some <span style=\"color: #000000; text-decoration-color: #000000; background-color: #ffff00\">malt Low bitterness</span>\n","</pre>\n"],"text/plain":["Not \u001b[30;48;2;255;255;0mtreated\u001b[0m before for for some reason Pale clear \u001b[30;48;2;255;255;0mblond Grassy aroma\u001b[0m of straw and some \u001b[30;48;2;255;255;0mmalt Low bitterness\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[('blond grassy aroma', 0.6178),\n"," ('malt low bitterness', 0.5016),\n"," ('treated', 0.2173)]\n"]}],"source":["# 최대최근 관련성\n","keywords = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 3), stop_words='english',\n","                           use_mmr=True, diversity=0.7, highlight=True, top_n=3)\n","pprint(keywords)"]},{"cell_type":"markdown","metadata":{},"source":["### - 특정 맥주에 대한 리뷰 키워드 추출"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[WinError 3] 지정된 경로를 찾을 수 없습니다: './Beer_Sentiment_analysis/Data'\n","c:\\Users\\Gyeom\\OneDrive - 한국항공대학교\\바탕 화면\\머신러닝\\프로젝트\\맥주 측면 감정 분석\\Beer_Sentiment_analysis\\Data\n"]}],"source":["cd \"./Beer_Sentiment_analysis/Data\""]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["from keybert import KeyBERT\n","from keyphrase_vectorizers import KeyphraseCountVectorizer # n_gram 대신 문맥, 문법을 고쳐주는 Vectorizer\n","import pandas as pd\n","from pprint import pprint # 출력 정리 라이브러리"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 721756377110786641\n","xla_global_id: -1\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 6284115968\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 6254377679399951221\n","physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n","xla_global_id: 416903419\n","]\n"]}],"source":["import os\n","from tensorflow.python.client import device_lib\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","print(device_lib.list_local_devices())"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["def extract_keywords_for_beer(doc):\n","    try:\n","        # 방법 1\n","        keywords1 = kw_model.extract_keywords(doc, vectorizer=KeyphraseCountVectorizer(), top_n=5)\n","        keywords1 = [keyword for keyword, score in keywords1]\n","\n","        # 방법 2\n","        keywords2 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 3), stop_words=\"english\",\n","                                use_maxsum=True, nr_candidates=20, top_n=3)\n","        keywords2 = [keyword for keyword, score in keywords2]\n","\n","        # 방법 3\n","        keywords3 = kw_model.extract_keywords(doc, keyphrase_ngram_range=(1, 3), stop_words=\"english\",\n","                                use_mmr=True, diversity=0.7, top_n=3)\n","        keywords3 = [keyword for keyword, score in keywords3]\n","\n","        # 결과를 하나의 리스트로 합치기\n","        keywords_combined = list(set(keywords1 + keywords2 + keywords3))\n","\n","    except ValueError:\n","        # 키워드를 찾지 못한 경우 빈 리스트 반환\n","        keywords_combined = []\n","\n","    return keywords_combined\n","\n","# 데이터 불러오기\n","df = pd.read_csv('Binary Classification_v3.csv')\n","\n","\n","############## 지정된 맥주 이름의 리뷰들 필터링 ##############\n","beer_names = ['Asahi Super Dry', '8 Wired iStout', 'Red Rock']\n","\n","# 해당하는 맥주 이름을 가진 리뷰들만 선택하기\n","selected_reviews = df[df['Beer_name'].isin(beer_names)]\n","selected_reviews.reset_index(drop = True,inplace = True)\n","##########################################################\n","\n","# KeyBERT 모델 생성\n","kw_model = KeyBERT(\"all-mpnet-base-v2\")\n","\n","\n","# 키워드 추출 함수 적용\n","selected_reviews['Keywords'] = selected_reviews['Review'].apply(extract_keywords_for_beer)\n","\n","# 결과 출력\n","selected_reviews\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["selected_reviews.to_csv('pp_ke_selected_reviews.csv', encoding='utf-8', index = False)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPmsSrGb7mV0FGt93zS/S/D","gpuType":"V100","mount_file_id":"1iKT_JZOP7RE34WTu8kEV1YM3Z4JhSg6b","provenance":[]},"kernelspec":{"display_name":"ml_3.10","language":"python","name":"ml_3.10"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
